{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/CheyneyComputerScience/CREMA-D/tree/master/docs#crema-d-crowd-sourced-emotional-multimodal-actors-dataset\n",
    "\n",
    "## Filename labeling conventions\n",
    "The Actor id is a 4 digit number at the start of the file. Each subsequent identifier is separated by an underscore (_).\n",
    "\n",
    "Actors spoke from a selection of 12 sentences (in parentheses is the three letter acronym used in the second part of the filename):\n",
    "\n",
    "* It's eleven o'clock (IEO).\n",
    "* That is exactly what happened (TIE).\n",
    "* I'm on my way to the meeting (IOM).\n",
    "* I wonder what this is about (IWW).\n",
    "* The airplane is almost full (TAI).\n",
    "* Maybe tomorrow it will be cold (MTI).\n",
    "* I would like a new alarm clock (IWL)\n",
    "* I think I have a doctor's appointment (ITH).\n",
    "* Don't forget a jacket (DFA).\n",
    "* I think I've seen this before (ITS).\n",
    "* The surface is slick (TSI).\n",
    "* We'll stop in a couple of minutes (WSI).\n",
    "\n",
    "The sentences were presented using different emotion (in parentheses is the three letter code used in the third part of the filename):\n",
    "\n",
    "* Anger (ANG)\n",
    "* Disgust (DIS)\n",
    "* Fear (FEA)\n",
    "* Happy/Joy (HAP)\n",
    "* Neutral (NEU)\n",
    "* Sad (SAD)\n",
    "\n",
    "and emotion level (in parentheses is the two letter code used in the fourth part of the filename):\n",
    "\n",
    "* Low (LO)\n",
    "* Medium (MD)\n",
    "* High (HI)\n",
    "* Unspecified (XX)\n",
    "\n",
    "The suffix of the filename is based on the type of file, flv for flash video used for presentation of both the video only, and the audio-visual clips. mp3 is used for the audio files used for the audio-only presentation of the clips. wav is used for files used for computational audio processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:16:53.909897Z",
     "iopub.status.busy": "2023-11-24T13:16:53.909605Z",
     "iopub.status.idle": "2023-11-24T13:16:57.252529Z",
     "shell.execute_reply": "2023-11-24T13:16:57.251445Z",
     "shell.execute_reply.started": "2023-11-24T13:16:53.909870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:17:14.948422Z",
     "iopub.status.busy": "2023-11-24T13:17:14.947651Z",
     "iopub.status.idle": "2023-11-24T13:17:39.933023Z",
     "shell.execute_reply": "2023-11-24T13:17:39.931887Z",
     "shell.execute_reply.started": "2023-11-24T13:17:14.948388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate librosa\n",
    "!pip install --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:17:39.935896Z",
     "iopub.status.busy": "2023-11-24T13:17:39.935122Z",
     "iopub.status.idle": "2023-11-24T13:18:11.973071Z",
     "shell.execute_reply": "2023-11-24T13:18:11.971894Z",
     "shell.execute_reply.started": "2023-11-24T13:17:39.935857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets==2.14.6\n",
    "!pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-24T13:18:35.756886Z",
     "iopub.status.busy": "2023-11-24T13:18:35.755592Z",
     "iopub.status.idle": "2023-11-24T13:18:35.764872Z",
     "shell.execute_reply": "2023-11-24T13:18:35.763788Z",
     "shell.execute_reply.started": "2023-11-24T13:18:35.756845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score\n",
    ")\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    AutoModelForAudioClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED=3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input/crema-d/CREMA-D-master/AudioMP3'):\n",
    "#     for filename in filenames:\n",
    "#         print(filename)\n",
    "save_path = \"/kaggle/working\"\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:18:43.888344Z",
     "iopub.status.busy": "2023-11-24T13:18:43.887503Z",
     "iopub.status.idle": "2023-11-24T13:19:52.114960Z",
     "shell.execute_reply": "2023-11-24T13:19:52.114006Z",
     "shell.execute_reply.started": "2023-11-24T13:18:43.888305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for path in tqdm(glob(\"/kaggle/input/d/return0root/crema-d/CREMA-D/AudioWAV/*.wav\")):\n",
    "    name = str(path).split('/')[-1].split('.')[0]\n",
    "    actor_id, sentence, emotion, level = name.split('_')\n",
    "    try:\n",
    "        y,sr = librosa.load(path, sr=16000)\n",
    "        data.append({\n",
    "            \"file\": path,\n",
    "            \"actor_id\": actor_id,\n",
    "            \"sentence\": sentence,\n",
    "            \"label\": emotion,\n",
    "            \"level\": level\n",
    "        })\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:20:22.815829Z",
     "iopub.status.busy": "2023-11-24T13:20:22.814986Z",
     "iopub.status.idle": "2023-11-24T13:20:22.831908Z",
     "shell.execute_reply": "2023-11-24T13:20:22.831098Z",
     "shell.execute_reply.started": "2023-11-24T13:20:22.815795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:20:25.303454Z",
     "iopub.status.busy": "2023-11-24T13:20:25.303108Z",
     "iopub.status.idle": "2023-11-24T13:20:25.316151Z",
     "shell.execute_reply": "2023-11-24T13:20:25.315107Z",
     "shell.execute_reply.started": "2023-11-24T13:20:25.303429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:20:50.988254Z",
     "iopub.status.busy": "2023-11-24T13:20:50.987876Z",
     "iopub.status.idle": "2023-11-24T13:20:52.251856Z",
     "shell.execute_reply": "2023-11-24T13:20:52.250334Z",
     "shell.execute_reply.started": "2023-11-24T13:20:50.988224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SentenceFilenames.csv - list of movie files used in study\n",
    "# finishedEmoResponses.csv - the first emotional response with timing.\n",
    "# finishedResponses.csv - the final emotional Responses with emotion levels with repeated and practice responses removed, used to tabulate the votes\n",
    "\n",
    "df_sentence = pd.read_csv('/kaggle/input/d/return0root/crema-d/CREMA-D/SentenceFilenames.csv')\n",
    "df_first_resp = pd.read_csv('/kaggle/input/d/return0root/crema-d/CREMA-D/finishedEmoResponses.csv')\n",
    "df_final_resp = pd.read_csv('/kaggle/input/d/return0root/crema-d/CREMA-D/finishedResponses.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:20:58.218452Z",
     "iopub.status.busy": "2023-11-24T13:20:58.217513Z",
     "iopub.status.idle": "2023-11-24T13:20:58.228647Z",
     "shell.execute_reply": "2023-11-24T13:20:58.227688Z",
     "shell.execute_reply.started": "2023-11-24T13:20:58.218413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_first_resp['numTries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:21:01.109961Z",
     "iopub.status.busy": "2023-11-24T13:21:01.109575Z",
     "iopub.status.idle": "2023-11-24T13:21:01.119469Z",
     "shell.execute_reply": "2023-11-24T13:21:01.118466Z",
     "shell.execute_reply.started": "2023-11-24T13:21:01.109930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_final_resp['numTries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:21:09.332577Z",
     "iopub.status.busy": "2023-11-24T13:21:09.331812Z",
     "iopub.status.idle": "2023-11-24T13:21:09.417981Z",
     "shell.execute_reply": "2023-11-24T13:21:09.416899Z",
     "shell.execute_reply.started": "2023-11-24T13:21:09.332532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(df, test_size=0.3, random_state=SEED,\n",
    "                                    stratify=df[\"label\"])\n",
    "dev_df, test_df = train_test_split(dev_df, test_size=0.5, random_state=SEED,\n",
    "                                   stratify=dev_df[\"label\"])\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "dev_df = dev_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# remove unused features in training models\n",
    "# train_df.drop(['actor_id','sentence', 'level'], axis=1, inplace=True)\n",
    "# dev_df.drop(['actor_id','sentence', 'level'], axis=1, inplace=True)\n",
    "# test_df.drop(['actor_id','sentence', 'level'], axis=1, inplace=True)\n",
    "\n",
    "train_df.to_csv(f\"{save_path}/train.csv\", encoding=\"utf-8\", index=False)\n",
    "dev_df.to_csv(f\"{save_path}/dev.csv\", encoding=\"utf-8\", index=False)\n",
    "test_df.to_csv(f\"{save_path}/test.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(dev_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:21:14.049518Z",
     "iopub.status.busy": "2023-11-24T13:21:14.048668Z",
     "iopub.status.idle": "2023-11-24T13:21:14.587985Z",
     "shell.execute_reply": "2023-11-24T13:21:14.587013Z",
     "shell.execute_reply.started": "2023-11-24T13:21:14.049484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": f\"{save_path}/train.csv\",\n",
    "    \"validation\": f\"{save_path}/dev.csv\",\n",
    "    \"test\": f\"{save_path}/test.csv\"\n",
    "}\n",
    "\n",
    "# train_dataset = train_df\n",
    "# dev_dataset = dev_df\n",
    "# test_dataset = test_df\n",
    "# label_list = sorted(train_dataset['label'].unique())\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "train_dataset = dataset[\"train\"]\n",
    "dev_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "label_list = sorted(train_dataset.unique('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:24:06.197091Z",
     "iopub.status.busy": "2023-11-24T13:24:06.196296Z",
     "iopub.status.idle": "2023-11-24T13:24:06.201882Z",
     "shell.execute_reply": "2023-11-24T13:24:06.200890Z",
     "shell.execute_reply.started": "2023-11-24T13:24:06.197059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Base = 90M parameters; Large = 300M parameters\n",
    "\n",
    "#model_name_or_path = \"facebook/wav2vec2-base-960h\" # “baseline” model; pre-trained on 960 hours of English\n",
    "model_name_or_path = \"facebook/wav2vec2-large-960h-lv60\"\n",
    "# model_name_or_path = \"facebook/wav2vec2-base-el-voxpopuli-v2\" # pre-trained on Greek speech, no fine-tuning\n",
    "# model_name_or_path = \"facebook/wav2vec2-large-el-voxpopuli-v2\" # pre-trained on Greek speech, no fine-tuning\n",
    "# model_name_or_path = \"facebook/wav2vec2-xls-r-300m\" # pre-trained on 0.5 million hours in multiple languages, no fine-tuning\n",
    "# model_name_or_path = \"lighteternal/wav2vec2-large-xlsr-53-greek\" # pre-trained on 50000 hours in multiple languages, Greek ASR fine-tuning\n",
    "\n",
    "# Feel free to look for and experiment with other models at HuggingFace Hub https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:24:09.863213Z",
     "iopub.status.busy": "2023-11-24T13:24:09.862333Z",
     "iopub.status.idle": "2023-11-24T13:24:37.293528Z",
     "shell.execute_reply": "2023-11-24T13:24:37.292750Z",
     "shell.execute_reply.started": "2023-11-24T13:24:09.863178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_extractor=AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "model=AutoModelForAudioClassification.from_pretrained(model_name_or_path,\n",
    "                                      num_labels=len(train_dataset.unique(\"label\")),\n",
    "                                      label2id={label: i for i, label in enumerate(label_list)},\n",
    "                                      id2label={i: label for i, label in enumerate(label_list)}\n",
    "                                      )\n",
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:24:49.202306Z",
     "iopub.status.busy": "2023-11-24T13:24:49.201404Z",
     "iopub.status.idle": "2023-11-24T13:24:49.208871Z",
     "shell.execute_reply": "2023-11-24T13:24:49.207998Z",
     "shell.execute_reply.started": "2023-11-24T13:24:49.202272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def label_to_id(label, label_list):\n",
    "    if len(label_list) > 0:\n",
    "        return label_list.index(label) if label in label_list else -1\n",
    "    return label\n",
    "def prepare_example(example):\n",
    "    example[\"audio\"], example[\"sampling_rate\"] = librosa.load(example[\"file\"], sr=feature_extractor.sampling_rate)\n",
    "    example[\"duration_in_seconds\"] = len(example[\"audio\"]) / feature_extractor.sampling_rate\n",
    "    example[\"label\"] = label_to_id(example[\"label\"], label_list)\n",
    "    return example\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays = examples[\"audio\"]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:44:44.315978Z",
     "iopub.status.busy": "2023-11-10T03:44:44.315678Z",
     "iopub.status.idle": "2023-11-10T03:44:44.324989Z",
     "shell.execute_reply": "2023-11-10T03:44:44.324003Z",
     "shell.execute_reply.started": "2023-11-10T03:44:44.315952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_dataset = train_dataset.map(prepare_example, remove_columns=['file'])\n",
    "# dev_dataset = dev_dataset.map(prepare_example, remove_columns=['file'])\n",
    "# test_dataset = test_dataset.map(prepare_example, remove_columns=['file'])\n",
    "# train_dataset = train_dataset.map(preprocess_function, batched=True, batch_size=1, remove_columns=['audio'])\n",
    "# dev_dataset = dev_dataset.map(preprocess_function, batched=True, batch_size=1, remove_columns=['audio'])\n",
    "# test_dataset = test_dataset.map(preprocess_function, batched=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:25:11.994344Z",
     "iopub.status.busy": "2023-11-24T13:25:11.993510Z",
     "iopub.status.idle": "2023-11-24T13:29:51.633811Z",
     "shell.execute_reply": "2023-11-24T13:29:51.633000Z",
     "shell.execute_reply.started": "2023-11-24T13:25:11.994311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(prepare_example, remove_columns=['file'])\n",
    "dataset = dataset.map(preprocess_function, batched=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:49:18.824445Z",
     "iopub.status.busy": "2023-11-10T03:49:18.824076Z",
     "iopub.status.idle": "2023-11-10T03:49:18.828701Z",
     "shell.execute_reply": "2023-11-10T03:49:18.827712Z",
     "shell.execute_reply.started": "2023-11-10T03:49:18.824409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# delete processed data\n",
    "# !rm -rf /kaggle/working/data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:31:08.611125Z",
     "iopub.status.busy": "2023-11-24T13:31:08.610700Z",
     "iopub.status.idle": "2023-11-24T13:31:14.606871Z",
     "shell.execute_reply": "2023-11-24T13:31:14.605717Z",
     "shell.execute_reply.started": "2023-11-24T13:31:08.611094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset.save_to_disk(f\"{save_path}/data/preprocessed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T13:31:32.639258Z",
     "iopub.status.busy": "2023-11-24T13:31:32.638871Z",
     "iopub.status.idle": "2023-11-24T13:31:32.810835Z",
     "shell.execute_reply": "2023-11-24T13:31:32.809897Z",
     "shell.execute_reply.started": "2023-11-24T13:31:32.639226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(f\"{save_path}/data/preprocessed/\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "dev_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "label_list = sorted(train_dataset.unique('label'))\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:49:23.82469Z",
     "iopub.status.busy": "2023-11-10T03:49:23.824366Z",
     "iopub.status.idle": "2023-11-10T03:49:23.863139Z",
     "shell.execute_reply": "2023-11-10T03:49:23.862286Z",
     "shell.execute_reply.started": "2023-11-10T03:49:23.824664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Batch size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "# Parameters to tune: learning rate, epochs, (batch size)\n",
    "# More details on hyperparameter tuning in https://github.com/google-research/tuning_playbook\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{save_path}/{model_name_or_path}-speech-emotion-recognition\",\n",
    "    per_device_train_batch_size=64, # require more GPU memory, this set can exploit 16GB memory\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=15,\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=1e-4,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    push_to_hub=False,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:49:23.864661Z",
     "iopub.status.busy": "2023-11-10T03:49:23.864318Z",
     "iopub.status.idle": "2023-11-10T03:49:23.875144Z",
     "shell.execute_reply": "2023-11-10T03:49:23.874407Z",
     "shell.execute_reply.started": "2023-11-10T03:49:23.864629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(pred.predictions, axis=1)\n",
    "    accuracy = accuracy_score(pred.label_ids, predictions)\n",
    "    precision = precision_score(pred.label_ids, predictions, average='macro')\n",
    "    recall = recall_score(pred.label_ids, predictions, average='macro')\n",
    "    f1 = f1_score(pred.label_ids, predictions, average='macro')\n",
    "    return {\"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:49:23.876821Z",
     "iopub.status.busy": "2023-11-10T03:49:23.876375Z",
     "iopub.status.idle": "2023-11-10T03:49:29.101816Z",
     "shell.execute_reply": "2023-11-10T03:49:29.100999Z",
     "shell.execute_reply.started": "2023-11-10T03:49:23.876786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:49:29.103332Z",
     "iopub.status.busy": "2023-11-10T03:49:29.103011Z",
     "iopub.status.idle": "2023-11-10T03:49:29.107963Z",
     "shell.execute_reply": "2023-11-10T03:49:29.106876Z",
     "shell.execute_reply.started": "2023-11-10T03:49:29.103306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T03:49:29.109446Z",
     "iopub.status.busy": "2023-11-10T03:49:29.109164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if training_args.load_best_model_at_end:\n",
    "    #trainer.evaluate(eval_dataset=test_dataset)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(compute_metrics(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    input_values = feature_extractor(batch[\"audio\"], sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values.to(device)).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"predictions\"] = predicted_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_names = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "result = test_dataset.map(map_to_pred)\n",
    "print(classification_report(result['label'], result['predictions'], target_names=label_names, digits=4))\n",
    "\n",
    "cm = confusion_matrix(result['label'], result['predictions'], normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=label_names)\n",
    "\n",
    "disp.plot(xticks_rotation = 'vertical')\n",
    "plt.title(f\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3979186,
     "sourceId": 6930154,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
